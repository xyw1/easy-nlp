{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "MAX_LENGTH = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解码器层\n",
    "\n",
    "\n",
    "解码器层结构如下:\n",
    "\n",
    "![](./images/image-20241103212541411.png)\n",
    "\n",
    "它的组成部分如下:\n",
    "1. embedding层\n",
    "2. GRU 层\n",
    "\n",
    "输入一个批次的文本,先通过Embedding层将其转化为向量。接着送入GRU神经网络, 最后返回当前时间步GRU的输出和隐藏状态\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(\n",
    "            input_size, hidden_size, device=device\n",
    "        )  # 词嵌入层\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, device=device)  # GRU层\n",
    "\n",
    "    def forward(self, input_tensor, hidden):\n",
    "        embedded = self.embedding(input_tensor).view(1, 1, -1)  # (1, 1, hidden_size)\n",
    "        output, hidden = self.gru(\n",
    "            embedded, hidden\n",
    "        )  # (1, 1, hidden_size) 和 (1, 1, hidden_size)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(\n",
    "            1, 1, self.hidden_size, device=device\n",
    "        )  # 初始化隐藏状态 (1, 1, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带注意力机制的解码器\n",
    "\n",
    "公式如下:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{Softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V\n",
    "$$\n",
    "\n",
    "这里的Attention类就是实现了上面的公式,用户只需要传入对应的QKV, 它就会返回一个经过注意力加权后的向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 带注意力机制的解码器\n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            output_size, hidden_size, device=device\n",
    "        )  # 词嵌入层\n",
    "        self.attn = nn.Linear(2 * hidden_size, max_length).to(device)  # 计算注意力权重\n",
    "        self.attn_combine = nn.Linear(2 * hidden_size, hidden_size).to(\n",
    "            device\n",
    "        )  # 合并嵌入向量和注意力加权值\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size).to(device)  # GRU层\n",
    "        self.dropout = nn.Dropout(dropout).to(device)  # Dropout层\n",
    "        self.linear = nn.Linear(hidden_size, output_size).to(device)  # 输出层\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.dropout(\n",
    "            self.embedding(input).view(1, 1, -1)\n",
    "        )  # (1, 1, hidden_size)\n",
    "\n",
    "        # 计算注意力权重\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), dim=1)), dim=1\n",
    "        )  # (1, max_length)\n",
    "\n",
    "        # 计算加权后的上下文向量\n",
    "        attn_applied = torch.bmm(\n",
    "            attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)\n",
    "        )  # (1, 1, hidden_size)\n",
    "\n",
    "        # 拼接嵌入向量和上下文向量\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)  # (1, 2 * hidden_size)\n",
    "        output = self.attn_combine(output).unsqueeze(0)  # (1, 1, hidden_size)\n",
    "        output = F.relu(output)  # (1, 1, hidden_size)\n",
    "\n",
    "        output, hidden = self.gru(\n",
    "            output, hidden\n",
    "        )  # (1, 1, hidden_size) 和 (1, 1, hidden_size)\n",
    "        output = self.linear(output[0])  # (1, output_size)\n",
    "        output = F.log_softmax(output, dim=1)  # (1, output_size)\n",
    "\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq网络\n",
    "\n",
    "结构如下:\n",
    "\n",
    "![](./images/Seq2SeqStruction.png)\n",
    "\n",
    "它的组成是:\n",
    "1. encode层\n",
    "2. decode层\n",
    "\n",
    "decode终止输出的情况有两种:\n",
    "1. 到达最大预测的长度\n",
    "2. 遇到结束符\n",
    "\n",
    "\n",
    "教师机制:\n",
    "\n",
    "在训练过程中，模型在初期阶段往往表现不佳，其输出结果可能频繁与正确答案不匹配，导致收敛速度较慢。为加速模型收敛，我们会在训练过程中适时地对输出进行合理的纠正，使模型逐步接近正确答案，从而提高训练效果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq模型\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor, teacher_forcing_ratio=0.5):\n",
    "        input_length = input_tensor.size(0)  # 输入序列的长度\n",
    "        target_length = target_tensor.size(0)  # 目标序列的长度\n",
    "\n",
    "        encoder_hidden = self.encoder.init_hidden()  \n",
    "        encoder_outputs = torch.zeros(\n",
    "            MAX_LENGTH, self.encoder.hidden_size, device=device\n",
    "        )  \n",
    "\n",
    "        # 编码阶段\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(\n",
    "                input_tensor[ei], encoder_hidden\n",
    "            )  # (1, 1, hidden_size) 和 (1, 1, hidden_size)\n",
    "            encoder_outputs[ei] = encoder_output[\n",
    "                0, 0\n",
    "            ]  # 取出每个时间步的输出 (MAX_LENGTH, hidden_size)\n",
    "\n",
    "        # 初始化解码器输入（开始符号）和隐藏状态\n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]], device=device)  # (1, 1)\n",
    "        decoder_hidden = encoder_hidden \n",
    "        # (target_length, output_size)\n",
    "        all_decoder_outputs = torch.zeros(\n",
    "            target_length, self.decoder.output_size, device=device\n",
    "        )  \n",
    "\n",
    "        use_teacher_force = random.random() < teacher_forcing_ratio  # 是否使用教师强制\n",
    "\n",
    "        # 解码阶段\n",
    "        for di in range(target_length):\n",
    "            # (1, output_size), (1, 1, hidden_size), (1, max_length)\n",
    "            decoder_output, decoder_hidden, attn_weights = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )  \n",
    "            # 存储每一步的输出 (target_length, output_size)\n",
    "            all_decoder_outputs[di] = (\n",
    "                decoder_output \n",
    "            )\n",
    "            # 获取最大概率的词索引\n",
    "            topv, topi = decoder_output.topk(1) \n",
    "            # 获取下一个时间步的输入 (1)\n",
    "            decoder_input = topi.squeeze().detach()  \n",
    "            # 使用真实标签作为下一步的输入\n",
    "            if use_teacher_force:\n",
    "                decoder_input = target_tensor[di]  \n",
    "        # (target_length, output_size)\n",
    "        return all_decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们自己模拟一些数据测试一下,看看整个网络能不能跑通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出的形状: torch.Size([10, 10])\n",
      "输出结果: tensor([[-2.2461, -2.2819, -2.4620, -2.2147, -2.4411, -2.2934, -2.2494, -2.1325,\n",
      "         -2.3702, -2.3839],\n",
      "        [-2.2118, -2.3072, -2.4071, -2.2543, -2.3731, -2.3399, -2.3419, -2.2153,\n",
      "         -2.2430, -2.3539],\n",
      "        [-2.2386, -2.2638, -2.3979, -2.2506, -2.3947, -2.3371, -2.3556, -2.1821,\n",
      "         -2.2624, -2.3682],\n",
      "        [-2.2188, -2.2772, -2.3897, -2.3419, -2.3797, -2.2719, -2.3886, -2.2583,\n",
      "         -2.1884, -2.3350],\n",
      "        [-2.2116, -2.1980, -2.3550, -2.3035, -2.3246, -2.2725, -2.4459, -2.2368,\n",
      "         -2.3017, -2.4052],\n",
      "        [-2.1951, -2.2575, -2.3521, -2.3529, -2.3478, -2.3122, -2.4296, -2.2681,\n",
      "         -2.2390, -2.2926],\n",
      "        [-2.2118, -2.2135, -2.3671, -2.3687, -2.3352, -2.2857, -2.3720, -2.2856,\n",
      "         -2.2745, -2.3280],\n",
      "        [-2.2952, -2.2617, -2.2988, -2.3434, -2.3602, -2.2751, -2.4099, -2.2849,\n",
      "         -2.2504, -2.2581],\n",
      "        [-2.2218, -2.2963, -2.3636, -2.3404, -2.3504, -2.2878, -2.4835, -2.2837,\n",
      "         -2.2238, -2.2054],\n",
      "        [-2.2192, -2.2480, -2.4887, -2.3497, -2.3826, -2.2983, -2.3577, -2.2555,\n",
      "         -2.2247, -2.2350]], device='cuda:0', grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "input_size = 10  # 输入词汇表大小\n",
    "output_size = 10  # 输出词汇表大小\n",
    "hidden_size = 256  # GRU的隐藏层大小\n",
    "batch_size = 1  # 测试时使用单个序列\n",
    "max_length = 10  # 输入和输出序列的最大长度\n",
    "teacher_forcing_ratio = 0.5  # 教师强制率，控制是否使用真实标签作为下一步的输入\n",
    "\n",
    "# 输入序列：形状为 (input_length, batch_size)\n",
    "input_tensor = torch.randint(\n",
    "    0, input_size, (max_length, 1), device=device\n",
    ")  \n",
    "# 目标序列：形状为 (target_length, batch_size)\n",
    "target_tensor = torch.randint(\n",
    "    0, output_size, (max_length, 1), device=device\n",
    ") \n",
    "\n",
    "# 初始化编码器、解码器和Seq2Seq模型\n",
    "encoder = Encoder(input_size, hidden_size).to(device)  \n",
    "decoder = AttentionDecoder(hidden_size, output_size).to(device)  \n",
    "seq2seq_model = Seq2Seq(encoder, decoder).to(device)  \n",
    "\n",
    "# 通过Seq2Seq模型进行前向传播\n",
    "output = seq2seq_model(input_tensor, target_tensor, teacher_forcing_ratio)\n",
    "\n",
    "\n",
    "print(\"输出的形状:\", output.shape)  \n",
    "print(\"输出结果:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
