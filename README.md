# Easy-NLP

本课程将带大家通过使用pytorch中的线性层来手搓传统NLP中的RNN, GRU, LSTM和带注意力机制的Seq2Seq模型, 帮助大家理解和入门传统的NLP模型。同时每个神经网络写好后都会结合一个实际的例子, 带大家了解这些模型是怎么训练的,以及如何对数据做预处理。



## 课程大纲

| 章节            | 内容                        | 备注                                                 |
| --------------- | ---------------------------| ---------------------------------------------------- |
| 1. 手搓 RNN     | 介绍 RNN 并从零开始构建      | 涵盖基础 RNN 单元结构、前向传播 
| 2. 手搓 LSTM    | 理解并实现 LSTM 单元         | 包括遗忘门、输入门、输出门，解释 LSTM 如何改进 RNN   |
| 3. 手搓 GRU     | GRU 结构及从零实现           | 重点介绍 GRU 的门控机制及其相较于 LSTM 的效率        |
| 4. 手搓 Seq2Seq | 构建用于序列预测的 Seq2Seq 模型 | 涵盖编码器-解码器结构，和注意力机制原理            |





## 参与贡献

- 如果你想参与到项目中来欢迎查看项目的 [Issue](https://github.com/datawhalechina/unlock-hf/issues) 查看没有被分配的任务✨。
- 如果你发现了一些问题，欢迎在 [Issue](https://github.com/datawhalechina/unlock-hf/issues) 中进行反馈🐛。

如果你对 Datawhale 很感兴趣并想要发起一个新的项目，欢迎查看 [Datawhale 贡献指南](https://github.com/datawhalechina/DOPMC#为-datawhale-做出贡献)。



## 贡献者名单

| 姓名 | 职责        | 简介       |
| :--- | :---------- | :--------- |
| 苏向标 | 项目负责人  | DataWhale 助教, 广州大学       |
| 徐韵婉 | 第1章贡献者 | DataWhale 助教,在职 |
| 杨卓 | 第2章贡献者 | DataWhale 意向成员, 西安电子科技大学 |
| 陈国威 | 第3章贡献者 | DataWhale 意向成员|
| 苏向标 | 第4章贡献者 |  |



## 关注我们

<div align=center>
<p>扫描下方二维码关注公众号：Datawhale</p>
<img src="https://raw.githubusercontent.com/datawhalechina/pumpkin-book/master/res/qrcode.jpeg" width = "180" height = "180">
</div>


## LICENSE

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。

*注：默认使用CC 4.0协议，也可根据自身项目情况选用其他协议*
